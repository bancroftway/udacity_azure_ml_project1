#Creating compute cluster

from azureml.core.compute_target import ComputeTargetException
cpu_cluster_name = "arvc-cpu-cluster"

# Verify that cluster does not exist already
try:
    cpu_cluster = ComputeTarget(workspace=ws, name=cpu_cluster_name)
    print('Found existing cluster, use it.')
except ComputeTargetException:
    compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_D2_V2', max_nodes=4)
    cpu_cluster = ComputeTarget.create(ws, cpu_cluster_name, compute_config)

cpu_cluster.wait_for_completion(show_output=True)


----------------------
# Specify parameter sampler
ps = RandomParameterSampling( {
        "--C": uniform(0.00, 2.5),
        "--max_iter": randint(500)
    }
)

# Specify a Policy
policy = BanditPolicy(evaluation_interval=2, slack_factor=0.1)

if "training" not in os.listdir():
    os.mkdir("./training")

# Create a SKLearn estimator for use with train.py
est = SKLearn(source_directory=".", compute_target=cpu_cluster, entry_script='train.py')

# Create a HyperDriveConfig using the estimator, hyperparameter sampler, and policy.
hyperdrive_config = HyperDriveConfig(estimator=est, hyperparameter_sampling=ps, policy=policy, primary_metric_name="Accuracy", 
primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, max_total_runs=50, max_concurrent_runs=10, max_duration_minutes=60)


------------------
hdr = exp.submit(config=hyperdrive_config)

RunDetails(hdr).show()
-------------------

best_run = hdr.get_best_run_by_primary_metric()

if best_run is None: 
    raise Exception("No best run was found")

parameter_values = best_run.get_details()['runDefinition']['arguments']

print(parameter_values)

best_run.register_model(model_name='arvc_best_model', model_path=os.path.abspath(os.path.join('outputs', 'arvc_best_model.pkl')))









-------------Auto ML------------------------
import pandas as pd
df = x.merge(y.rename('y'), left_index=True, right_index=True)


--------------
automl_config = AutoMLConfig(
    experiment_timeout_minutes=30,
    task='classification',
    primary_metric='AUC_weighted',
    training_data=df,
    label_column_name='y',
    compute_target = cpu_cluster,
    n_cross_validations=10)
    
   
   
-------------------------
automl_run = exp.submit(automl_config, show_output=True)































